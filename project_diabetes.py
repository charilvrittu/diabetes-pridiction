# -*- coding: utf-8 -*-
"""Project_Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXz1nuuwOgLVmdI8hoWc4FMPHUfeO8Xq

Step 0: Import headerfiles
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn import preprocessing

"""Step 1 : read dataset

step 1.1: read dataset from drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""step 1.2 :copy path of dataset"""

data=pd.read_csv('/content/drive/MyDrive/Share diabetes.csv')
data

"""step 2 :Information about the dataset or Exploratory data Analysis

step 2.1:using shape method to find no of rows and columns
"""

data.shape

"""step 2.2: using info to print datails of dataset"""

data.info()

"""step 2.3: to print top 5 rows details of dataset info"""

data.head()

"""step 2.4: to print last row datails and distributions of dataset"""

data.tail()

"""step 2.5: to print manipulated outcomes of dataset

---



---


"""

data.describe()

"""0 indicates --No diabetes
1 indicates--diabetes

Step 2.6:To count no of rows with particular value in Pregnancies column
"""

data["Pregnancies"].value_counts()

"""step 2.7:To count no of rows with particular value in Insulin column"""

data["Insulin"].value_counts()

"""step 2.8:To find max,min,average value of Insulin column"""

# See the min, max, mean values
print('The highest insulin was of:',data['Insulin'].max())
print('The lowest insulin was of:',data['Insulin'].min())
print('The average insulin in the data:',data['Insulin'].mean())

"""step 2.9:To find max,min,average value of Blood Pressure column"""

# See the min, max, mean values
print('The highest BloodPressure was of:',data['BloodPressure'].max())
print('The lowest BloodPressure was of:',data['BloodPressure'].min())
print('The average BloodPressure in the data:',data['BloodPressure'].mean())

"""Step 3 :VISUALISATION
```

```

Step 3.1:Graph of all parameter and outcome
"""

data.hist(figsize=(50,40),color="#0000FF",edgecolor='black')

"""Step 3.2:Indivitual graph for Glucose column"""

# visualization
plt.plot(data['Glucose'])
plt.xlabel("Glucose")
plt.ylabel("Levels")
plt.title("Glucose Line Plot")
plt.show()

"""Step 3.3: Graph on diabetes outcome based on glucose level"""

fig,(ax1,ax2)=plt.subplots(1,2,figsize=(13,5))
newdataset_len=data[data['Outcome']==1]['Glucose'].value_counts()

ax1.hist(newdataset_len,color='blue')
ax1.set_title('Having Diabetes')

newdataset_len=data[data['Outcome']==0]['Glucose'].value_counts()
ax2.hist(newdataset_len,color='yellow')
ax2.set_title('NOT Having Diabetes')

fig.suptitle('Glucose Levels')
plt.show()

"""Step 3.4:Indivitual graph for BloodPressure column"""

plt.plot(data['BloodPressure'])
plt.xlabel("BloodPressure")
plt.ylabel("Levels")
plt.title(" BloodPressure Line Plot")
plt.show()

"""Step 3.5:Indivitual graph for Insulin column"""

plt.plot(data['Insulin'])
plt.xlabel("Insulin")
plt.ylabel("Levels")
plt.title("Insulin Line Plot")
plt.show()

"""Step 4:PREPROCESSING

Step 4.1:Check for duplicate rows
"""

data.duplicated()

"""#NO DUPLICATE VALUES IN DATA SET

Step 4.2:Check for null values
"""

data.isnull().sum()

"""Step 5: Train-Test Split  (90:10 ratio)

STEP 6.1:Import necessary libraries for model training and evaluation
"""

from sklearn.model_selection import train_test_split #training and testing data split
from sklearn import metrics #accuracy measure
from sklearn.metrics import confusion_matrix
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score, classification_report #for confusion matrix
from sklearn.linear_model import LogisticRegression,LinearRegression #logistic regression

"""Step 6.2:For storing columns names"""

feature_names = data.columns.tolist()
feature_names

"""Step 6.3:Logistic regression(Finding accuracy and Confusion matrix)"""

from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'classification' is a variable containing the target column name
classification = 'Outcome'

# Select features (X) and target variable (y)
feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
X = data[feature_columns]
y = data[classification]

# Replace '\t?' with NaN
X.replace('\t?', np.nan, inplace=True)

# Convert columns to numeric (assuming that they are numeric features)
X = X.apply(pd.to_numeric, errors='coerce')

# Impute missing values using the mean strategy
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Split the data into training and testing sets
train_X, test_X, train_Y, test_Y = train_test_split(X_imputed, y, test_size=0.1, random_state=0)

# Initialize and train the Logistic Regression model
model = LogisticRegression()
model.fit(train_X, train_Y)

# Make predictions on the test set
predictions = model.predict(test_X)

# Evaluate the model
accuracy = metrics.accuracy_score(predictions, test_Y)
print('The accuracy of the Logistic Regression model is:', accuracy)

# Display the classification report and confusion matrix
report = classification_report(test_Y, predictions)
print("Classification Report:\n", report)

cm = confusion_matrix(test_Y, predictions, labels=model.classes_)
cmap = plt.cm.get_cmap('PuBu')
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap=cmap)
plt.show()

"""Step 6.4: Display Logistic Regression results

"""

import matplotlib.pyplot as plt
import numpy as np

# Replace these values with your actual scores
precision = [0.87, 0.86]
recall = [0.94, 0.73]
f1_score = [0.91, 0.79]

labels = ['Class 0', 'Class 1']

# Plotting the bar chart
width = 0.2
x = np.arange(len(labels))

fig, ax = plt.subplots()
rects1 = ax.bar(x - width, precision, width, label='Precision')
rects2 = ax.bar(x, recall, width, label='Recall')
rects3 = ax.bar(x + width, f1_score, width, label='F1-Score')

# Adding labels, title, and legend
ax.set_ylabel('Scores')
ax.set_title('Logistic Regression Model Evaluation Metrics')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

# Display the plot
plt.show()

"""Step 6.5:  Linear regression implementation"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming train_X, train_Y, test_X, test_Y are your training and testing data

# Split the data into training and testing sets
train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.1, random_state=0)

# Create a linear regression model
model = LinearRegression()

# Fit the model to the training data
model.fit(train_X, train_Y)

# Make predictions on the test set
predictions = model.predict(test_X)

# Convert predictions to discrete classes (assuming a classification scenario)
predictions_classes = np.round(predictions).astype(int)

# Evaluate the model using accuracy (not typical for linear regression)
accuracy = accuracy_score(test_Y, predictions_classes)

print('Accuracy:', accuracy)

"""Step 7:receiver operating characteristic curve of logistic"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Assuming 'classification' is a variable containing the target column name
classification = 'Outcome'

# ... (your previous code)

# Split the data into training and testing sets
train_X, test_X, train_Y, test_Y = train_test_split(X_imputed, y, test_size=0.1, random_state=0)

# Initialize and train the Logistic Regression model
model = LogisticRegression()
model.fit(train_X, train_Y)

# Make predictions on the test set
predictions = model.predict(test_X)

# Ensure test_Y and predictions are of the correct type
test_Y = test_Y.values.ravel()  # Convert to 1D array
predictions = predictions.ravel()  # Convert to 1D array

# Continue with your code
# ROC Curve for Logistic Regression
fpr, tpr, _ = roc_curve(test_Y, predictions)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Logistic Regression')
plt.legend(loc="lower right")
plt.show()

"""Step 8: Comparision graph between linear and logistic graph"""

fig = plt.figure(figsize = (7, 5))
models = ["Linear Regression", "Logistic Regresion"]
plt.bar(models, accuracy, width = 0.2, color='#c8a2c8')
plt.xlabel("Models", fontsize = 15,color="#533153")
plt.ylabel("Accuracy", fontsize = 15,color="#533153")
plt.xticks()
plt.show()